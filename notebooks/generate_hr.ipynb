{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN CODE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# normalize the Hr data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created successfully or already exists.\n"
     ]
    }
   ],
   "source": [
    "# create a directory to store the generated files\n",
    "try:\n",
    "    os.makedirs(\"../generated_data/train/\", exist_ok=True)\n",
    "    os.makedirs(\"../generated_data/test/\", exist_ok=True)\n",
    "    \n",
    "    os.makedirs(\"../generated_data/train/Hr\", exist_ok=True)\n",
    "    os.makedirs(\"../generated_data/test/Hr\", exist_ok=True)\n",
    "    \n",
    "    os.makedirs(\"../generated_data/train/HaHb\", exist_ok=True)\n",
    "    os.makedirs(\"../generated_data/test/HaHb\", exist_ok=True)\n",
    "    print(\"Directory created successfully or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HaHb_array(data,hydropathy_scale):\n",
    "    HaHb_list = []\n",
    "    #print(len(HaHb_list))\n",
    "    # For one scale get all HaHb values\n",
    "    # iterate over the dataset\n",
    "    for i in range(data.shape[0]):\n",
    "        row = data.iloc[i]\n",
    "        resA_ = row['resA']\n",
    "        resB_ = row['resB']\n",
    "        resB_1 = row['resB_1']\n",
    "        resB_2 = row['resB_2']\n",
    "        resB_3 = row['resB_3']\n",
    "        resB_4 = row['resB_4']\n",
    "        resB_5 = row['resB_5']\n",
    "        resB_6 = row['resB_6']\n",
    "        resB_7 = row['resB_7']\n",
    "        resB_8 = row['resB_8']\n",
    "        resB_9 = row['resB_9']\n",
    "\n",
    "        # get values from the scale\n",
    "        resA_scale_value = hydropathy_scale[resA_].iloc[0]\n",
    "        resB_scale_value = hydropathy_scale[resB_].iloc[0]\n",
    "        resB_1_scale_value = hydropathy_scale[resB_1].iloc[0]\n",
    "        resB_2_scale_value = hydropathy_scale[resB_2].iloc[0]\n",
    "        resB_3_scale_value = hydropathy_scale[resB_3].iloc[0]\n",
    "        resB_4_scale_value = hydropathy_scale[resB_4].iloc[0]\n",
    "        resB_5_scale_value = hydropathy_scale[resB_5].iloc[0]\n",
    "        resB_6_scale_value = hydropathy_scale[resB_6].iloc[0]\n",
    "        resB_7_scale_value = hydropathy_scale[resB_7].iloc[0]\n",
    "        resB_8_scale_value = hydropathy_scale[resB_8].iloc[0]\n",
    "        resB_9_scale_value = hydropathy_scale[resB_9].iloc[0]\n",
    "\n",
    "        # calculate HaHb values\n",
    "        currentcombination = [resA_scale_value*resB_scale_value, \n",
    "        resA_scale_value*resB_1_scale_value, \n",
    "        resA_scale_value*resB_2_scale_value, \n",
    "        resA_scale_value*resB_3_scale_value, \n",
    "        resA_scale_value*resB_4_scale_value, \n",
    "        resA_scale_value*resB_5_scale_value, \n",
    "        resA_scale_value*resB_6_scale_value, \n",
    "        resA_scale_value*resB_7_scale_value, \n",
    "        resA_scale_value*resB_8_scale_value, \n",
    "        resA_scale_value*resB_9_scale_value]\n",
    "\n",
    "        HaHb_list.append(currentcombination)\n",
    "    \n",
    "    data = np.array(HaHb_list)\n",
    "    print(data.shape)\n",
    "    # Find the minimum value in the array\n",
    "    min_value = np.min(data)\n",
    "\n",
    "    # Shift the array values to be all positive\n",
    "    shifted_data = data - min_value\n",
    "    print(shifted_data.shape)\n",
    "\n",
    "    return shifted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_for_abc(HaHb_min,HaHb_max,HaHb_median):\n",
    "    x1 = HaHb_min\n",
    "    x2 = HaHb_max\n",
    "    x3 = HaHb_median\n",
    "    A = np.array([\n",
    "        [-x1**2, x1, 1],\n",
    "        [-x2**2, x2, 1],\n",
    "        [-x3**2, x3, 1]\n",
    "    ])\n",
    "    \n",
    "    # Constants matrix\n",
    "    B = np.array([0, 0, 1])\n",
    "    \n",
    "    # Solving the system of equations\n",
    "    solution = np.linalg.solve(A, B)\n",
    "    a, b, c = solution\n",
    "    # print(a,b,c)\n",
    "    return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_values_for_abc(HaHb_max,HaHb_min,HaHb_median):\\n    x1 = HaHb_min\\n    x2 = HaHb_max\\n    x3 = HaHb_median\\n\\n    a = -1 / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\\n    b = (- (x1 + x2)) / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\\n    c = (x1 * x2) / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\\n    return a,b,c'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_values_for_abc(HaHb_max,HaHb_min,HaHb_median):\n",
    "    x1 = HaHb_min\n",
    "    x2 = HaHb_max\n",
    "    x3 = HaHb_median\n",
    "\n",
    "    a = -1 / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\n",
    "    b = (- (x1 + x2)) / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\n",
    "    c = (x1 * x2) / (x1 * x2 - x1 * x3 - x2 * x3 + x3**2)\n",
    "    return a,b,c\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the main dataset\n",
    "filename = \"../dataset/train/dataset.txt\"\n",
    "dataset = pd.read_csv(filename)\n",
    "\n",
    "# drop the pdb column\n",
    "data = dataset.drop(columns=['pdb'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resA</th>\n",
       "      <th>resB</th>\n",
       "      <th>resB_1</th>\n",
       "      <th>resB_2</th>\n",
       "      <th>resB_3</th>\n",
       "      <th>resB_4</th>\n",
       "      <th>resB_5</th>\n",
       "      <th>resB_6</th>\n",
       "      <th>resB_7</th>\n",
       "      <th>resB_8</th>\n",
       "      <th>resB_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIS</td>\n",
       "      <td>HIS</td>\n",
       "      <td>THR</td>\n",
       "      <td>GLN</td>\n",
       "      <td>ASP</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ILE</td>\n",
       "      <td>PRO</td>\n",
       "      <td>TYR</td>\n",
       "      <td>VAL</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLU</td>\n",
       "      <td>GLY</td>\n",
       "      <td>PRO</td>\n",
       "      <td>SER</td>\n",
       "      <td>GLU</td>\n",
       "      <td>PHE</td>\n",
       "      <td>LEU</td>\n",
       "      <td>TYR</td>\n",
       "      <td>THR</td>\n",
       "      <td>GLU</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHE</td>\n",
       "      <td>VAL</td>\n",
       "      <td>ILE</td>\n",
       "      <td>SER</td>\n",
       "      <td>LEU</td>\n",
       "      <td>VAL</td>\n",
       "      <td>ASP</td>\n",
       "      <td>GLU</td>\n",
       "      <td>PHE</td>\n",
       "      <td>ILE</td>\n",
       "      <td>GLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLU</td>\n",
       "      <td>LYS</td>\n",
       "      <td>LEU</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ALA</td>\n",
       "      <td>ARG</td>\n",
       "      <td>GLU</td>\n",
       "      <td>GLU</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ASP</td>\n",
       "      <td>ASP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLY</td>\n",
       "      <td>THR</td>\n",
       "      <td>GLU</td>\n",
       "      <td>ARG</td>\n",
       "      <td>PHE</td>\n",
       "      <td>THR</td>\n",
       "      <td>ARG</td>\n",
       "      <td>GLN</td>\n",
       "      <td>PHE</td>\n",
       "      <td>SER</td>\n",
       "      <td>LEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resA resB resB_1 resB_2 resB_3 resB_4 resB_5 resB_6 resB_7 resB_8 resB_9\n",
       "0  HIS  HIS    THR    GLN    ASP    LEU    ILE    PRO    TYR    VAL    ARG\n",
       "1  GLU  GLY    PRO    SER    GLU    PHE    LEU    TYR    THR    GLU    ARG\n",
       "2  PHE  VAL    ILE    SER    LEU    VAL    ASP    GLU    PHE    ILE    GLU\n",
       "3  GLU  LYS    LEU    LEU    ALA    ARG    GLU    GLU    LEU    ASP    ASP\n",
       "4  GLY  THR    GLU    ARG    PHE    THR    ARG    GLN    PHE    SER    LEU"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the test dataset\n",
    "# read the main dataset\n",
    "filename = \"../dataset/test/dataset.txt\"\n",
    "dataset_test = pd.read_csv(filename)\n",
    "\n",
    "# drop the pdb column\n",
    "data_test = dataset_test.drop(columns=['pdb'], axis=1)\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4272, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resA</th>\n",
       "      <th>resB</th>\n",
       "      <th>resB_1</th>\n",
       "      <th>resB_2</th>\n",
       "      <th>resB_3</th>\n",
       "      <th>resB_4</th>\n",
       "      <th>resB_5</th>\n",
       "      <th>resB_6</th>\n",
       "      <th>resB_7</th>\n",
       "      <th>resB_8</th>\n",
       "      <th>resB_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRP</td>\n",
       "      <td>LEU</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ILE</td>\n",
       "      <td>TRP</td>\n",
       "      <td>MET</td>\n",
       "      <td>ILE</td>\n",
       "      <td>TYR</td>\n",
       "      <td>LYS</td>\n",
       "      <td>ILE</td>\n",
       "      <td>TRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THR</td>\n",
       "      <td>HIS</td>\n",
       "      <td>GLY</td>\n",
       "      <td>GLY</td>\n",
       "      <td>VAL</td>\n",
       "      <td>THR</td>\n",
       "      <td>GLY</td>\n",
       "      <td>VAL</td>\n",
       "      <td>ILE</td>\n",
       "      <td>THR</td>\n",
       "      <td>ASP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LYS</td>\n",
       "      <td>HIS</td>\n",
       "      <td>ASP</td>\n",
       "      <td>THR</td>\n",
       "      <td>GLU</td>\n",
       "      <td>LYS</td>\n",
       "      <td>ARG</td>\n",
       "      <td>TYR</td>\n",
       "      <td>GLU</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ASN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LYS</td>\n",
       "      <td>HIS</td>\n",
       "      <td>PHE</td>\n",
       "      <td>CYS</td>\n",
       "      <td>PHE</td>\n",
       "      <td>THR</td>\n",
       "      <td>CYS</td>\n",
       "      <td>TRP</td>\n",
       "      <td>GLU</td>\n",
       "      <td>GLY</td>\n",
       "      <td>ASN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAL</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ALA</td>\n",
       "      <td>LYS</td>\n",
       "      <td>LEU</td>\n",
       "      <td>VAL</td>\n",
       "      <td>GLU</td>\n",
       "      <td>LEU</td>\n",
       "      <td>ASP</td>\n",
       "      <td>SER</td>\n",
       "      <td>SER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resA resB resB_1 resB_2 resB_3 resB_4 resB_5 resB_6 resB_7 resB_8 resB_9\n",
       "0  TRP  LEU    LEU    ILE    TRP    MET    ILE    TYR    LYS    ILE    TRP\n",
       "1  THR  HIS    GLY    GLY    VAL    THR    GLY    VAL    ILE    THR    ASP\n",
       "2  LYS  HIS    ASP    THR    GLU    LYS    ARG    TYR    GLU    LEU    ASN\n",
       "3  LYS  HIS    PHE    CYS    PHE    THR    CYS    TRP    GLU    GLY    ASN\n",
       "4  VAL  LEU    ALA    LYS    LEU    VAL    GLU    LEU    ASP    SER    SER"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined = pd.concat([data, data_test], axis=0)\n",
    "print(data_combined.shape)\n",
    "data_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669fa5461fc84bc682627eb59dd6832d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "Processing file: ../hydropathy/GOLD730101.csv\n",
      "Error calculating values for a, b, c: Singular matrix\n",
      "Skipping this iteration due to singular matrix.\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n",
      "(2990, 10)\n",
      "(2990, 10)\n",
      "(1282, 10)\n",
      "(1282, 10)\n",
      "(4272, 10)\n",
      "(4272, 10)\n"
     ]
    }
   ],
   "source": [
    "# loop through hydropathy folder and pick scale one by one, generate HaHb values and save them in a list\n",
    "# iterate over the directory\n",
    "directory = \"../hydropathy/\"\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for file_path in tqdm(os.listdir(directory)):\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # calculate HaHb\n",
    "    # final list to save the HaHb values\n",
    "    HaHb_list = []\n",
    "\n",
    "    hydropathy_scale = pd.read_csv(directory + file_path,header = None)\n",
    "    hydropathy_scale.columns = ['aa', 'hydropathy']\n",
    "\n",
    "    # typecast hydropathy values to float\n",
    "    hydropathy_scale['hydropathy'] = hydropathy_scale['hydropathy'].astype(float)\n",
    "\n",
    "    hydropathy_scale = hydropathy_scale.T\n",
    "    # make first row as header\n",
    "    new_header = hydropathy_scale.iloc[0]\n",
    "    hydropathy_scale = hydropathy_scale[1:]\n",
    "    hydropathy_scale.columns = new_header\n",
    "    hydropathy_scale.reset_index(drop=True, inplace=True)\n",
    "    #print(\"train\")\n",
    "    # for training data\n",
    "    HaHb_train = get_HaHb_array(data,hydropathy_scale)\n",
    "\n",
    "    #print(\"test\")\n",
    "    # for test data\n",
    "    HaHb_test = get_HaHb_array(data_test,hydropathy_scale)\n",
    "    \n",
    "    #print(\"combined\")\n",
    "    # for a,b,c calculation\n",
    "    HaHb_combined = get_HaHb_array(data_combined,hydropathy_scale)\n",
    "    #print(HaHb.shape)\n",
    "    \n",
    "    # apply log transformation on HaHb_combined\n",
    "    #HaHb_combined = np.log(HaHb_combined)\n",
    "\n",
    "    # get mid,min and max values of HaHb\n",
    "    HaHb_min = np.min(HaHb_combined)\n",
    "    HaHb_max = np.max(HaHb_combined)\n",
    "    \n",
    "    # --------------------------- NEW UPDATE -------------------------------------\n",
    "    # consider data from 5 to 75 percentile\n",
    "    HaHb_filtered = HaHb_combined[(HaHb_combined >= np.percentile(HaHb_combined, 5)) & (HaHb_combined <= np.percentile(HaHb_combined, 75))]\n",
    "    HaHb_median = np.median(HaHb_filtered)\n",
    "    #print(HaHb_median)\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "    #print(HaHb.shape)\n",
    "    # calculate Hr\n",
    "    try:\n",
    "        # pre normalization\n",
    "        a, b, c = get_values_for_abc(HaHb_max, HaHb_min, HaHb_median)\n",
    "        \n",
    "        # saving value to print later\n",
    "        a_, b_, c_ = get_values_for_abc(HaHb_max, HaHb_min, HaHb_median)\n",
    "\n",
    "        # save file_path,a_,b_,c_ values in a text file\n",
    "        with open(\"a_b_c.txt\", \"a\") as f:\n",
    "            f.write(f\"{file_path},{a_},{b_},{c_}\\n\")\n",
    "        \n",
    "        \n",
    "        # post normalization\n",
    "        #a,b,c = round(a/4,3),round(b/4,3),round(c/4,3)\n",
    "        #print(\"after normalizaion\",a,b,c)\n",
    "\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(f\"Processing file: {directory+file_path}\")\n",
    "        print(f\"Error calculating values for a, b, c: {e}\")\n",
    "        print(\"Skipping this iteration due to singular matrix.\")\n",
    "        #print(HaHb)\n",
    "        continue\n",
    "    \n",
    "    # get Hr values\n",
    "    Hr = np.array(list(map(lambda HaHb_train: (-a * (HaHb_train ** 2)) + ((b * HaHb_train) + c), HaHb_train.flatten()))).reshape(HaHb_train.shape)\n",
    "    Hr_test = np.array(list(map(lambda HaHb_test: (-a * (HaHb_test ** 2)) + ((b * HaHb_test) + c), HaHb_test.flatten()))).reshape(HaHb_test.shape)\n",
    "\n",
    "    # normalize the Hr values\n",
    "    Hr_train_norm = scaler.fit_transform(Hr)\n",
    "    Hr_test_norm = scaler.fit_transform(Hr_test)\n",
    "\n",
    "    #if Hr_train_norm has anu -ve values print file_path\n",
    "    if np.any(HaHb_train < 0):\n",
    "        print(f\"Negative values found in Hr_train_norm for file: {file_path}\")\n",
    "        #print(Hr_train_norm\n",
    "    if np.any(HaHb_test < 0):\n",
    "        print(f\"Negative values found in Hr_test_norm for file: {file_path}\")\n",
    "        #print(Hr_test_norm)\n",
    "\n",
    "    # save train hr files\n",
    "    file_name = file_path.replace('.csv', '')\n",
    "    np.savetxt(f\"../generated_data/train/HaHb/{file_name}.txt\", HaHb_train)\n",
    "    np.savetxt(f\"../generated_data/train/Hr/{file_name}.txt\", Hr_train_norm)\n",
    "    # save test hr files\n",
    "    np.savetxt(f\"../generated_data/test/HaHb/{file_name}.txt\", HaHb_test)\n",
    "    np.savetxt(f\"../generated_data/test/Hr/{file_name}.txt\", Hr_test_norm)\n",
    "    \n",
    "    #print(\"________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional visualization and testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Hr_L_hydrophobicity_scale.txt file\n",
    "Hr = np.loadtxt(\"../generated_data/train/Hr/L_hydrophobicity_scale.txt\")\n",
    "\n",
    "# read /Users/pulkit/Desktop/mini_project/dsmp-2024-groupt3/dataset/train/hr.txt file\n",
    "hr = np.loadtxt(\"../dataset/train/hr.txt\")\n",
    "\n",
    "print(\"For generated and original Hr\")\n",
    "print(\"generated\",np.min(Hr), np.max(Hr), np.median(Hr))\n",
    "print(\"original\",np.min(hr), np.max(hr), np.median(hr))    \n",
    "\n",
    "print(Hr.shape)\n",
    "print()\n",
    "print(hr.shape)\n",
    "\n",
    "print(Hr)\n",
    "print()\n",
    "print(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to compute H_A * H_B given H_r, a, and b\n",
    "def compute_HA_HB(H_r_values, a, b):\n",
    "    H_A_H_B_values = []\n",
    "    \n",
    "    for H_r in H_r_values:\n",
    "        # Compute the discriminant\n",
    "        discriminant = b**2 - 4 * a * H_r\n",
    "\n",
    "        if discriminant < 0:\n",
    "            # No real solution; return NaN or handle differently\n",
    "            H_A_H_B_values.append(np.nan)\n",
    "        else:\n",
    "            # Compute the two possible solutions\n",
    "            root1 = (b + np.sqrt(discriminant)) / (2 * a)\n",
    "            root2 = (b - np.sqrt(discriminant)) / (2 * a)\n",
    "            \n",
    "            # Choose the valid root (positive or within a reasonable range)\n",
    "            H_A_H_B = root1 if root1 >= 0 else root2\n",
    "            H_A_H_B_values.append(H_A_H_B)\n",
    "    \n",
    "    return np.array(H_A_H_B_values)\n",
    "\n",
    "# Example dataset: Given H_r values, a and b from one hydropathy scale\n",
    "# min max and median values of Hr\n",
    "H_r_example = [np.min(hr), np.max(hr), np.median(hr)]  # Example H_r values\n",
    "a_example = 0.033  # Example a value from a hydropathy scale\n",
    "b_example = 0.363  # Example b value from a hydropathy scale\n",
    "\n",
    "# Compute H_A * H_B values\n",
    "H_A_H_B_computed = compute_HA_HB(H_r_example, a_example, b_example)\n",
    "H_A_H_B_computed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read Hr_L_hydrophobicity_scale.txt file original\n",
    "Hr_generated = np.loadtxt(\"../generated_data/train/Hr/L_hydrophobicity_scale.txt\")\n",
    "\n",
    "# read Hr_L_hydrophobicity_scale.txt file original\n",
    "Hr_original =np.loadtxt(\"../dataset/train/hr.txt\")\n",
    "\n",
    "# HaHb_L_hydrophobicity_scale.txt file original\n",
    "HaHb = np.loadtxt(\"../generated_data/train/HaHb/L_hydrophobicity_scale.txt\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot for Generated Hr vs HaHb\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Hr_generated.flatten(), HaHb.flatten(), label='Generated Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Generated Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Generated)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot for Original Hr vs HaHb\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Hr_original.flatten(), HaHb.flatten(), label='Original Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Original Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Original)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the array\n",
    "Hr_generated_normalized = scaler.fit_transform(Hr_generated)\n",
    "\n",
    "\n",
    "plt.scatter(Hr_generated_normalized.flatten(), HaHb.flatten(), label='Generated Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Generated Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Generated)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Normalize the Hr array\n",
    "Hr_generated_normalized = scaler.fit_transform(Hr_generated)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot for Generated Hr vs HaHb\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Hr_generated_normalized.flatten(), HaHb.flatten(), label='Generated Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Generated Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Generated)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot for Original Hr vs HaHb\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Hr_original.flatten(), HaHb.flatten(), label='Original Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Original Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Original)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Hr_generated_normalized[0])\n",
    "print(\"--------------------------------\")\n",
    "print()\n",
    "print(Hr_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    " \n",
    "# Example data\n",
    "data = Hr_generated\n",
    " \n",
    "# Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "robust_scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot for Generated Hr vs HaHb\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(robust_scaled.flatten(), HaHb.flatten(), label='Generated Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Generated Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Generated)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot for Original Hr vs HaHb\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Hr_original.flatten(), HaHb.flatten(), label='Original Hr vs HaHb', alpha=0.5)\n",
    "plt.title(\"Original Hr vs HaHb\")\n",
    "plt.xlabel(\"Hr (Original)\")\n",
    "plt.ylabel(\"HaHb\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hr_generated_normalized[0][1] - Hr_original[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hr[0][0] - hr[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_original = 0.033\n",
    "b_original = 0.363\n",
    "a_calculated = 0.132 \n",
    "b_calculated = 1.456\n",
    "\n",
    "a_calculated/a_original, b_calculated/b_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset: Given H_r values, a and b from one hydropathy scale\n",
    "# min max and median values of Hr\n",
    "H_r_example = [np.min(Hr), np.max(Hr), np.median(Hr)]  # Example H_r values\n",
    "a_example = 0.033  # Example a value from a hydropathy scale\n",
    "b_example = 0.363  # Example b value from a hydropathy scale\n",
    "\n",
    "# Compute H_A * H_B values\n",
    "H_A_H_B_computed = compute_HA_HB(H_r_example, a_example, b_example)\n",
    "H_A_H_B_computed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sclae file： [ 1.41824591  5.24243582 -5.11380416 -5.89382492  6.02764359 -0.72872686\n",
      " -2.27717033  6.34590405 -5.66471605  5.0928903   3.46664162 -4.23048941\n",
      " -0.4819167  -4.69258733 -7.41894613 -2.29324688 -0.76510997  4.92625187\n",
      "  4.89540484  2.14512074]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA is to find the direction (primary component) of the largest variance in the data, \n",
    "# and use projections in these directions to represent the data, \n",
    "# thereby reducing redundant information and retaining the main features of the data as much as possible in the lower dimensional space.\n",
    "\n",
    "# set orders\n",
    "amino_acids = ['ALA', 'CYS', 'ASP', 'GLU', 'PHE', 'GLY', 'HIS', 'ILE', 'LYS', 'LEU',\n",
    "               'MET', 'ASN', 'PRO', 'GLN', 'ARG', 'SER', 'THR', 'VAL', 'TRP', 'TYR']\n",
    "\n",
    "# Read all 28 hydrophilic scales\n",
    "hydropathy_scales = []\n",
    "\n",
    "scale_files = os.listdir(\"../hydropathy\")\n",
    "for scale_file in scale_files:\n",
    "    df = pd.read_csv(f\"../hydropathy/{scale_file}\", delimiter=\",\", header=None, index_col=0)\n",
    "    df = df.loc[amino_acids]  # Arrange amino acids in a unified order\n",
    "    hydropathy_scales.append(df[1].values)  # get value \n",
    "\n",
    "# Convert all scale data into a matrix（形状：20×28，即 20 种氨基酸 × 28 个尺度）\n",
    "scale_matrix = np.array(hydropathy_scales).T  # 转置使得行为氨基酸，列为不同尺度\n",
    "\n",
    "#print(\"亲水性尺度矩阵形状：\", scale_matrix.shape)  # (20, 28)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Standardized data\n",
    "scaler = StandardScaler()\n",
    "scale_matrix_std = scaler.fit_transform(scale_matrix)\n",
    "\n",
    "# 2. PCA dimensionality reduction (only take the first principal component)\n",
    "pca = PCA(n_components=1)\n",
    "principal_component = pca.fit_transform(scale_matrix_std)  # Calculate principal components\n",
    "\n",
    "# 3. generate new scale\n",
    "new_hydropathy_scale = principal_component.flatten()  # Flattening into 1D array\n",
    "print(\"New Sclae file：\", new_hydropathy_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
